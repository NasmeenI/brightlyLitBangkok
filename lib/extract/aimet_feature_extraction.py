# -*- coding: utf-8 -*-
"""AIMET Feature Extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LohihmCU1h6x6s9kxYAVRoGPHeVgnGk9

# **Setups**
"""

# !pip install aiohttp
# !pip install aiolimiter
# !pip install aiodns
# !pip install tiktoken

"""**Imports**"""

import csv
import time
import os
import aiohttp
import asyncio
import json
import tiktoken
import pandas as pd
from tqdm import tqdm
from typing import List, Callable, Dict, Any
from dotenv import load_dotenv

"""**Octopus Api**

Slightly adjust from  [source](https://pypi.org/project/octopus-api/). The original source use asyncio.run() which will not work in jupyter notebook.
"""


class TentacleSession(aiohttp.ClientSession):
    """TentacleSession is a wrapper around the aiohttp.ClientSession, where it introduces the retry and rate functionality
    missing in the default aiohttp.ClientSession.

       Args:
           sleep (float): The time the client will sleep after each request. \n
           retries (int): The number of retries for a successful request. \n
           retry_sleep (float): The time service sleeps between nonsuccessful request calls. Defaults to 1.0.

       Returns:
           TentacleSession(aiohttp.ClientSession)
    """

    retries: int
    retry_sleep: float = 1.0

    def __init__(self, retries=3, retry_sleep=1.0, **kwargs):
        self.retries = retries
        self.retry_sleep = retry_sleep
        super().__init__(raise_for_status=True, **kwargs)

    def __retry__(self, func, **kwargs) -> Any:
        attempts = 0
        error = Exception()
        while attempts < self.retries:
            try:
                return func(**kwargs)
            except Exception as error:
                attempts += 1
                error = error
                time.sleep(self.retry_sleep)

        raise error

    def get(self, **kwargs) -> Any:
        return self.__retry__(func=super().get, **kwargs)

    def patch(self, **kwargs) -> Any:
        return self.__retry__(func=super().patch, **kwargs)

    def post(self, **kwargs) -> Any:
        return self.__retry__(func=super().post, **kwargs)

    def put(self, **kwargs) -> Any:
        return self.__retry__(func=super().put, **kwargs)

    def request(self, **kwargs) -> Any:
        return self.__retry__(func=super().request, **kwargs)


class OctopusApi:
    """Initiates the Octopus client.
    Args:
        rate (Optional[float]): The rate limits of the endpoint; default to no limit. \n
            resolution (Optional[str]): The time resolution of the rate (sec, minute), defaults to None.
            connections (Optional[int]): Maximum connections on the given endpoint, defaults to 5.

    Returns:
        OctopusApi
    """

    rate_sec: float = None
    connections: int
    retries: int

    def __init__(
        self,
        rate: int = None,
        resolution: str = None,
        connections: int = 5,
        retries: int = 3,
    ):

        if rate or resolution:
            if resolution.lower() not in ["minute", "sec"]:
                raise ValueError(
                    "Incorrect value of resolution, expecting minute or sec!"
                )
            if not rate:
                raise ValueError("Can not set resolution of rate without rate")
            self.rate_sec = rate / (60 if resolution.lower() == "minute" else 1)

        self.connections = connections
        self.retries = retries

    def get_coroutine(self, requests_list: List[Dict[str, Any]], func: callable):

        async def __tentacles__(
            rate: float,
            retries: int,
            connections: int,
            requests_list: List[Dict[str, Any]],
            func: callable,
        ) -> List[Any]:

            responses_order: Dict = {}
            progress_bar = tqdm(total=len(requests_list))
            sleep = 1 / rate if rate else 0

            async def func_mod(session: TentacleSession, request: Dict, itr: int):
                resp = await func(session, request)
                responses_order[itr] = resp
                progress_bar.update()

            conn = aiohttp.TCPConnector(limit_per_host=connections)
            async with TentacleSession(
                retries=retries,
                retry_sleep=sleep * self.connections * 2.0 if rate else 1.0,
                connector=conn,
            ) as session:

                tasks = set()
                itr = 0
                for request in requests_list:
                    if len(tasks) >= self.connections:
                        _done, tasks = await asyncio.wait(
                            tasks, return_when=asyncio.FIRST_COMPLETED
                        )
                    tasks.add(asyncio.create_task(func_mod(session, request, itr)))
                    await asyncio.sleep(sleep)
                    itr += 1
                await asyncio.wait(tasks)
                return [value for (key, value) in sorted(responses_order.items())]

        return __tentacles__(
            self.rate_sec, self.retries, self.connections, requests_list, func
        )

    async def execute(
        self, requests_list: List[Dict[str, Any]], func: callable
    ) -> List[Any]:
        """Execute the requests given the functions instruction.

        Empower asyncio libraries for performing parallel executions of the user-defined function.
        Given a list of requests, the result is ordered list of what the user-defined function returns.

        Args:
            requests_list (List[Dict[str, Any]): The list of requests in a dictionary format, e.g.
            [{"url": "http://example.com", "params": {...}, "body": {...}}..]
            func (callable): The user-defined function to execute, this function takes in the following arguments.
                Args:
                    session (TentacleSession): The Octopus wrapper around the aiohttp.ClientSession.
                    request (Dict): The request within the requests_list above.

        Returns:
            List(func->return)
        """

        result = await self.get_coroutine(requests_list, func)
        if result:
            return result
        return []


"""**Create  ChatGPT-related functions**"""

load_dotenv()

api_base_url = os.getenv("AZURE_OPENAI_ENDPOINT")
api_key = os.getenv("AZURE_OPENAI_KEY")
# api_base_url = userdata.get("AZURE_OPENAI_ENDPOINT")
# api_key = userdata.get("AZURE_OPENAI_KEY")
api_version = "2023-05-15"
chat_deployment_name = "gpt-35-turbo-4k-dev"
embeddings_deployment_name = "text-embedding-ada-002-dev"

full_chat_url = f"{api_base_url}/openai/deployments/{chat_deployment_name}/chat/completions?api-version={api_version}"
full_embeddings_url = f"{api_base_url}/openai/deployments/{embeddings_deployment_name}/embeddings?api-version={api_version}"
gpt_headers = {"Content-Type": "application/json", "api-key": api_key}

client = OctopusApi(rate=0.75, connections=10, resolution="sec", retries=3)


async def getMultipleChatCompletionMessage(histories) -> List[str]:
    async def chatCompletion(session: TentacleSession, request: Dict):
        result = None
        try:
            print(full_chat_url)
            async with session.post(
                url=full_chat_url, json=request["data"], headers=gpt_headers
            ) as response:
                result = await response.json()
        except Exception as err:
            print(err)
            pass
        return result

    result = await client.execute(
        requests_list=[{"data": x} for x in histories], func=chatCompletion
    )
    # see pricing https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/
    prompt_tokens = sum(
        map(lambda x: 0 if x is None else x["usage"]["prompt_tokens"], result)
    )
    prompt_tokens_price = 0.003 * prompt_tokens / 1000
    completion_tokens = sum(
        map(lambda x: 0 if x is None else x["usage"]["completion_tokens"], result)
    )
    completion_tokens_price = 0.004 * completion_tokens / 1000
    print("")  # new line
    print(prompt_tokens, "prompt tokens:", prompt_tokens_price, "$")
    print(completion_tokens, "completion tokens:", completion_tokens_price, "$")
    print("total price:", prompt_tokens_price + completion_tokens_price, "$")
    return list(
        map(
            lambda x: None if x is None else x["choices"][0]["message"]["content"],
            result,
        )
    )


async def getMultipleEmbeddings(messages: List[str]) -> List[List[float]]:
    async def embeddings(session: TentacleSession, request: Dict):
        result = None
        try:
            async with session.post(
                url=full_embeddings_url, json=request["data"], headers=gpt_headers
            ) as response:
                result = await response.json()
                result = result["data"][0]["embedding"]
        except:
            pass
        return result

    result = await client.execute(
        requests_list=[{"data": x} for x in messages], func=embeddings
    )
    return result


"""**Utility Functions**


"""


def utf8len(s: str) -> int:
    """Get bytes count of string
    see https://stackoverflow.com/a/30686735
    """
    return len(s.encode("utf-8"))


def num_tokens_from_string(string: str, encoding_name="cl100k_base") -> int:
    """Returns the number of tokens in a text string."""
    encoding = tiktoken.get_encoding(encoding_name)
    num_tokens = len(encoding.encode(string))
    return num_tokens




